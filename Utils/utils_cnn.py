# Author : Charles-Henry Bertrand Van Ouytsel
# Taken from https://gist.github.com/willwest/fcb61b110b9f7f59db40 , https://medium.com/@mrgarg.rajat/training-on-large-datasets-that-dont-fit-in-memory-in-keras-60a974785d71
import csv
import numpy as np
from sklearn.model_selection import GridSearchCV
from keras.utils import Sequence
from skimage.io import imread
from skimage.transform import resize

'''Exports a CSV of the GridCV scores and parameters.
gs_clf: A GridSearchCV object which has been fitted
export_file: A file path
'''
def print_GridCV_scores(gs_clf, export_file):

    with open(export_file, 'w') as outfile:
        csvwriter = csv.writer(outfile, delimiter=',')

        # Create the header using the parameter names 
        header = ["mean","std"]
        param_names = [param for param in gs_clf.param_grid]
        header.extend(param_names)

        csvwriter.writerow(header)

        for config in gs_clf.grid_scores_:
            # Get mean and standard deviation
            mean = config[1]
            std = np.std(config[2])
            row = [mean,std]

            # Get the list of parameter settings and add to row
            params = [str(p) for p in config[0].values()]
            row.extend(params)

            csvwriter.writerow(row)

'''Exports a CSV of the scores obtained after training and testing on a dataset.
gs_clf: A GridSearchCV object which has been fitted
export_file: A file path
'''
def print_score(clf,scores, export_file):

    with open(export_file, 'w') as outfile:
        csvwriter = csv.writer(outfile, delimiter=',')

        # Create the header
        names = [param for param in clf.metrics_names]

        csvwriter.writerow(names)
        csvwriter.writerow(scores)
        
class My_Custom_Generator(Sequence) :
  
  def __init__(self, directory, dimension, image_filenames, labels, batch_size) :
    self.directory = directory
    self.image_filenames = image_filenames
    self.labels = labels
    self.batch_size = batch_size
    self.dimension = dimension
    
    
  def __len__(self) :
    return (np.ceil(len(self.image_filenames) / float(self.batch_size))).astype(np.int)
  
  
  def __getitem__(self, idx) :
    batch_x = self.image_filenames[idx * self.batch_size : (idx+1) * self.batch_size]
    batch_y = self.labels[idx * self.batch_size : (idx+1) * self.batch_size]
    
    array_x = []
    for file_name in batch_x:
        img = imread(self.directory+'/' + str(file_name))
        rows,cols,colors = img.shape 
        img_size = rows*cols*colors
        img_1D_vector = img.reshape(img_size)
        array_x.append(img_1D_vector)
    return np.array([resize(img_x, self.dimension) for img_x in array_x])/255.0, np.array(batch_y)
    
class Generator_1D(My_Custom_Generator) :
  
  def __getitem__(self, idx) :
    batch_x = self.image_filenames[idx * self.batch_size : (idx+1) * self.batch_size]
    batch_y = self.labels[idx * self.batch_size : (idx+1) * self.batch_size]
    
    return np.array([resize(imread(self.directory+'/' + str(file_name)), self.dimension) for file_name in batch_x])/255.0, np.array(batch_y)
