# Author : Charles-Henry Bertrand Van Ouytsel
# Taken from https://gist.github.com/willwest/fcb61b110b9f7f59db40 , https://medium.com/@mrgarg.rajat/training-on-large-datasets-that-dont-fit-in-memory-in-keras-60a974785d71
import csv
import tensorflow
import numpy as np
from tensorflow.keras.layers import Input
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras import metrics as metr
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.layers import Dense, Dropout, Flatten, Softmax
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Conv1D, MaxPooling1D
from sklearn.model_selection import GridSearchCV
from tensorflow.keras.utils import Sequence
from skimage.io import imread
from skimage.transform import resize

NUM_CLASS =90
'''Exports a CSV of the GridCV scores and parameters.
gs_clf: A GridSearchCV object which has been fitted
export_file: A file path
'''
def print_GridCV_scores(gs_clf, export_file):

    with open(export_file, 'w') as outfile:
        csvwriter = csv.writer(outfile, delimiter=',')

        # Create the header using the parameter names 
        header = ["mean","std"]
        param_names = [param for param in gs_clf.param_grid]
        header.extend(param_names)

        csvwriter.writerow(header)

        for config in gs_clf.grid_scores_:
            # Get mean and standard deviation
            mean = config[1]
            std = np.std(config[2])
            row = [mean,std]

            # Get the list of parameter settings and add to row
            params = [str(p) for p in config[0].values()]
            row.extend(params)

            csvwriter.writerow(row)

def malware_model(optimizer='adam',learn_rate=0.001,dropout1=0.25,dropout2=0.5,neurons1=512,neurons2=256):
    if optimizer == 'SGD':
        lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(learn_rate,decay_steps=100000,decay_rate=0.96,staircase=True)
        opt = tensorflow.keras.optimizers.SGD(lr=lr_schedule, nesterov=True)
    else :   
        opt = tensorflow.keras.optimizers.Adam(learning_rate=learn_rate)
    Malware_model = Sequential()
    Malware_model.add(Conv2D(30, kernel_size=(3, 3),
                     activation='relu',
                     input_shape=(512,512,3)))
    Malware_model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
    Malware_model.add(Conv2D(15, (3, 3), activation='relu'))
    Malware_model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
    if dropout1 !=0.0:    
        Malware_model.add(Dropout(dropout1))
    Malware_model.add(Flatten())
    Malware_model.add(Dense(neurons1, activation='relu'))
    if dropout2 !=0.0:    
        Malware_model.add(Dropout(dropout2))
    Malware_model.add(Dense(neurons2, activation='relu'))
    #Malware_model.add(Dropout(j))
    Malware_model.add(Dense(NUM_CLASS, activation='softmax'))
    Malware_model.compile(loss='categorical_crossentropy', optimizer = opt, metrics=['accuracy',metr.Precision(),metr.Recall()])
    return Malware_model


def malware_model_1D(optimizer='adam',learn_rate=0.001,dropout1=0.25,dropout2=0.5,neurons1=512,neurons2=256):
    if optimizer == 'SGD':
        lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(learn_rate,decay_steps=100000,decay_rate=0.96,staircase=True)
        opt = tensorflow.keras.optimizers.SGD(lr=lr_schedule, nesterov=True)
    else :   
        opt = tensorflow.keras.optimizers.Adam(learning_rate=learn_rate)
    Malware_model = Sequential()
    Malware_model.add(Conv1D(30, kernel_size=3,
                     activation='relu',
                     input_shape=(512,512,3)))
    Malware_model.add(MaxPooling1D(pool_size=2, padding='same'))
    Malware_model.add(Conv1D(15, kernel_size=3, activation='relu'))
    Malware_model.add(MaxPooling1D(pool_size=2, padding='same'))
    if dropout1 !=0.0:
        Malware_model.add(Dropout(dropout1))
    Malware_model.add(Flatten())
    Malware_model.add(Dense(neurons1, activation='relu'))
    if dropout2 !=0.0:
        Malware_model.add(Dropout(dropout2))
    Malware_model.add(Dense(neurons2, activation='relu'))
    #Malware_model.add(Dropout(j))
    Malware_model.add(Dense(NUM_CLASS, activation='softmax'))

    Malware_model.compile(loss='categorical_crossentropy', optimizer = opt, metrics=['accuracy',metr.Precision(),metr.Recall()])
    return Malware_model


'''Exports a CSV of the scores obtained after training and testing on a dataset.
gs_clf: A GridSearchCV object which has been fitted
export_file: A file path
'''
def print_score(clf,scores, export_file):

    with open(export_file, 'w') as outfile:
        csvwriter = csv.writer(outfile, delimiter=',')

        # Create the header
        names = [param for param in clf.metrics_names]

        csvwriter.writerow(names)
        csvwriter.writerow(scores)
        
class My_Custom_Generator(Sequence) :
  
  def __init__(self, directory, dimension, image_filenames, labels, batch_size) :
    self.directory = directory
    self.image_filenames = image_filenames
    self.labels = labels
    self.batch_size = batch_size
    self.dimension = dimension
    
    
  def __len__(self) :
    return (np.ceil(len(self.image_filenames) / float(self.batch_size))).astype(np.int)
  
  
  def __getitem__(self, idx) :
    batch_x = self.image_filenames[idx * self.batch_size : (idx+1) * self.batch_size]
    batch_y = self.labels[idx * self.batch_size : (idx+1) * self.batch_size]
    
    array_x = []
    for file_name in batch_x:
        img = imread(self.directory+'/' + str(file_name))
        rows,cols,colors = img.shape 
        img_size = rows*cols*colors
        img_1D_vector = img.reshape(img_size)
        array_x.append(img_1D_vector)
    return np.array([resize(img_x, self.dimension) for img_x in array_x])/255.0, np.array(batch_y)
    
class Generator_1D(My_Custom_Generator) :
  
  def __getitem__(self, idx) :
    batch_x = self.image_filenames[idx * self.batch_size : (idx+1) * self.batch_size]
    batch_y = self.labels[idx * self.batch_size : (idx+1) * self.batch_size]
    
    return np.array([resize(imread(self.directory+'/' + str(file_name)), self.dimension) for file_name in batch_x])/255.0, np.array(batch_y)
