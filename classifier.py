"""
	Classifier - CNN
	Classify images from different families with a CNN for the private Cisco dataset

	Author: Benoit Michel
	Date : June 2021
"""

#from numpy.random import seed
#seed(1)
#from tensorflow import set_random_seed
#set_random_seed(2)

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import tensorflow
import tensorflow.compat.v1 as tf
#tf.disable_v2_behavior()
import tensorflow.keras as keras
#sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))

from tensorflow.keras.wrappers.scikit_learn import KerasClassifier

import seaborn as sns
from tensorflow.keras.layers import Input
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras import metrics as metr
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.layers import Dense, Dropout, Flatten, Softmax
from tensorflow.keras.layers import Conv2D, MaxPooling2D
#from tensorflow.keras.layers.normalization import BatchNormalization
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import train_test_split
from sklearn.utils import class_weight, shuffle
from sklearn import metrics
from PIL import Image
import time
import argparse
import os
import shutil
from PIL import ImageFile
from Utils.utils_cnn import print_GridCV_scores,print_score,My_Custom_Generator, Generator_1D,malware_model_1D
from datetime import datetime
ImageFile.LOAD_TRUNCATED_IMAGES = True

Image.MAX_IMAGE_PIXELS = None # To avoid warnings with big images

""" Arguments management """
parser = argparse.ArgumentParser(prog='classifier.py', description="Convert binary file to image")
parser.add_argument("input", help="Input directory path for images. This directory should contain several directories with names related to labels of images")
parser.add_argument("--save", help="Save model trained")
parser.add_argument("--generate", help="Generate dataset for cross validation in this directory", default=None)
parser.add_argument("--grid_search", help="Launch grid search to find optimal hyperparameters", action='store_true')
parser.add_argument("--out", help="Filename used to store results (default timestamp.csv )", default=datetime.now().strftime("%m-%d-%Y-%H:%M:%S")+'.csv')
parser.add_argument("--one_dim", help="Use CNN in 1D", action='store_true')
args = parser.parse_args()

if args.generate:
    train_dir = args.input
    dest_dir = args.generate
    if not os.path.exists(args.generate):
        os.mkdir(args.generate)
    counter = 0

    for subdir, dirs, files in os.walk(train_dir):
        for file in files:
            full_path = os.path.join(subdir, file)
            shutil.copy(full_path, dest_dir)
            counter = counter + 1  
    print('Copy ok !')
    filenames = []
    labels = np.zeros((counter, 1))

    filenames_counter = 0
    labels_counter = -1

    for subdir, dirs, files in os.walk(train_dir):
        for file in files:
            filenames.append(file)
            labels[filenames_counter, 0] = labels_counter
            filenames_counter = filenames_counter + 1
        labels_counter = labels_counter+1
        
    np.save(args.generate+'/filenames.npy', filenames)

    # One hot vector representation of labels
    y_labels_one_hot = to_categorical(labels)

    # saving the y_labels_one_hot array as a .npy file
    np.save(args.generate+'/y_labels_one_hot.npy', y_labels_one_hot)
    filenames_shuffled, y_labels_one_hot_shuffled = shuffle(filenames, y_labels_one_hot)

    # saving the shuffled file.
    # you can load them later using np.load().
    np.save(args.generate+'/y_labels_one_hot_shuffled.npy', y_labels_one_hot_shuffled)
    np.save(args.generate+'/filenames_shuffled.npy', filenames_shuffled)
    
    filenames_shuffled_numpy = np.array(filenames_shuffled)

    X_train_filenames, X_val_filenames, y_train, y_val = train_test_split(
        filenames_shuffled_numpy, y_labels_one_hot_shuffled, test_size=0.2, random_state=1)

    # You can save these files as well. As you will be using them later for training and validation of your model.
    np.save(args.generate+'/X_train_filenames.npy', X_train_filenames)
    np.save(args.generate+'/y_train.npy', y_train)

    np.save(args.generate+'/X_val_filenames.npy', X_val_filenames)
    np.save(args.generate+'/y_val.npy', y_val)
    dir_data = args.generate
else:
    X_train_filenames = np.load(args.input+'X_train_filenames.npy')
    y_train = np.load(args.input+'y_train.npy')
    X_val_filenames = np.load(args.input+'X_val_filenames.npy')
    y_val = np.load(args.input+'y_val.npy')
    dir_data = args.input

print('Building generator')
batch_size = 16
if args.one_dim:
    my_training_batch_generator = Generator_1D(dir_data,(262144,3),X_train_filenames, y_train, batch_size)
    my_validation_batch_generator = Generator_1D(dir_data,(262144,3),X_val_filenames, y_val, batch_size)    
else :
    my_training_batch_generator = My_Custom_Generator(dir_data,(256,256,3),X_train_filenames, y_train, batch_size)
    my_validation_batch_generator = My_Custom_Generator(dir_data,(256,256,3),X_val_filenames, y_val, batch_size)
num_classes = y_train.shape[1]
#NUM_CLASS = num_classes
print(num_classes)
#batches = ImageDataGenerator().flow_from_directory(directory=args.input, target_size=(224,224), batch_size=10000) # TODO : DISCUSS THIS TARGET SIZE !


#imgs, labels = next(batches)

#classes = batches.class_indices.keys()
#perc = (sum(labels)/labels.shape[0])*100

def malware_model(optimizer='adam',learn_rate=0.001,dropout1=0.25,dropout2=0.5,neurons1=512,neurons2=256):
    if optimizer == 'SGD':
        lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(learn_rate,decay_steps=100000,decay_rate=0.96,staircase=True)
        opt = tensorflow.keras.optimizers.SGD(lr=lr_schedule, nesterov=True)
    else :   
        opt = tensorflow.keras.optimizers.Adam(learning_rate=learn_rate)
    Malware_model = Sequential()
    Malware_model.add(Conv2D(30, kernel_size=(3, 3),
                     activation='relu',
                     input_shape=(256,256,3)))
    Malware_model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
    Malware_model.add(Conv2D(15, (3, 3), activation='relu'))
    Malware_model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
    if dropout1 !=0.0:    
        Malware_model.add(Dropout(dropout1))
    Malware_model.add(Flatten())
    Malware_model.add(Dense(neurons1, activation='relu'))
    if dropout2 !=0.0:    
        Malware_model.add(Dropout(dropout2))
    Malware_model.add(Dense(neurons2, activation='relu'))
    #Malware_model.add(Dropout(j))
    Malware_model.add(Dense(num_classes, activation='softmax'))
    Malware_model.compile(loss='categorical_crossentropy', optimizer = opt, metrics=['accuracy',metr.Precision(),metr.Recall()])
    return Malware_model



if args.grid_search:
    """ GRID SEARCH CONFIGURATION """
    print('Let\'s start grid search !')
    # define the grid search parameters
    if args.one_dim:
        model = KerasClassifier(build_fn=malware_model_1D, verbose=0)
    else:
        model = KerasClassifier(build_fn=malware_model, verbose=0)
    optimizer = ['SGD','adam']
    learn_rate = [0.001, 0.01, 0.1]
    #batch_size = [40, 60, 80, 100]
    dropout = [0.0,0.25,0.5,0.75]
    neurons = [128,256,512,1024,2048,4096]
    param_grid = dict(learn_rate=learn_rate, optimizer=optimizer,dropout1=dropout,dropout2=dropout,neurons1=neurons,neurons2=neurons)
    #param_grid = dict(optimizer=optimizer)
    grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)
    grid_result = grid.fit(my_training_batch_generator,steps_per_epoch= int(y_train.shape[0]//batch_size), validation_data=my_validation_batch_generator,validation_steps= int(y_val.shape[0]//batch_size), epochs=20, verbose=1)


    print("Best: %f using %s" % (grid_result.best_score_, grid_result.best_params_))
    means = grid_result.cv_results_['mean_test_score']
    stds = grid_result.cv_results_['std_test_score']
    params = grid_result.cv_results_['params']
    for mean, stdev, param in zip(means, stds, params):
        print("%f (%f) with: %r" % (mean, stdev, param))
    print_GridCV_scores(grid,args.out)
    exit(0)



accuracies = list()

#X_train, X_test, y_train, y_test = train_test_split(imgs/255.,labels, test_size=0.3) # Divided by 255 to have feature btw 0 and 1

if args.one_dim:
    Malware_model = malware_model_1D()
else:
    Malware_model = malware_model()
Malware_model.summary()


es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)
print('Start training of the model !')
Malware_model.fit(my_training_batch_generator,steps_per_epoch= int(y_train.shape[0]//batch_size), validation_data=my_validation_batch_generator,validation_steps= int(y_val.shape[0]//batch_size), epochs=20, verbose=1, callbacks=[es])
scores = Malware_model.evaluate(my_validation_batch_generator)


print('Final CNN accuracy: ', scores[1])
accuracies.append(scores[1])

if args.save:
    Malware_model.save(args.save)
    
print_score(Malware_model,scores,args.out)


"""
# Confusion matrix
y_pred = Malware_model.predict_classes(X_test, verbose=0)
y_test2 = np.argmax(y_test, axis=1)
c_matrix = metrics.confusion_matrix(y_test2, y_pred)

def confusion_matrix(confusion_matrix, class_names, figsize = (10,7), fontsize=14):

    df_cm = pd.DataFrame(
        confusion_matrix, index=class_names, columns=class_names,
    )
    fig = plt.figure(figsize=figsize)
    try:
        heatmap = sns.heatmap(df_cm, annot=True, fmt="d")
    except ValueError:
        raise ValueError("Confusion matrix values must be integers.")
    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)
    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)
    plt.ylabel('True label')
    plt.xlabel('Predicted label')
    plt.show()

class_names= batches.class_indices.keys()
confusion_matrix(c_matrix, class_names, figsize = (20,7), fontsize=14)"""
